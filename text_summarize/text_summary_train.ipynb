{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00dd96f7-b494-4533-b691-36c34d36affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dataclasses import replace\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c6062c9-ca98-4c55-9bb0-9b05e29b83d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/e1430a14/.conda/envs/notebook/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/scratch/e1430a14/.conda/envs/notebook/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import evaluate\n",
    "from transformers import T5ForConditionalGeneration, T5TokenizerFast\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "from transformers import TrainerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd1f0d0-7102-4edc-8436-6f9945551f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04cc185f-4acd-4e4d-b096-e8170082a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vetorizer(IterableDataset):\n",
    "    def __init__(self, tokenizer, dataset, seq_length, total_count):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.dataset = dataset\n",
    "        self.seq_length = seq_length\n",
    "        self.total_count = total_count\n",
    "    \n",
    "    def __iter__(self):\n",
    "        iterator = iter(self.dataset)\n",
    "        while True:\n",
    "            try:\n",
    "                data = next(iterator)\n",
    "                data['text'][0] = \"summarize: \" + data['text'][0]\n",
    "                text_concatenated = \" \".join(data['text'])\n",
    "                label = data['label']\n",
    "                text_tokenized = tokenizer(text_concatenated, padding='max_length', max_length=self.seq_length['encoder'], truncation=True)\n",
    "                label_tokenized = tokenizer(label, padding='max_length', max_length=self.seq_length['decoder'], truncation=True)\n",
    "                data = {\n",
    "                    'input_ids': text_tokenized['input_ids'],\n",
    "                    'attention_mask': text_tokenized['attention_mask'],\n",
    "                    'labels': label_tokenized['input_ids'],\n",
    "                }\n",
    "                yield data\n",
    "            except StopIteration:\n",
    "                iterator = iter(self.dataset)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9557feb-8e6e-4a5d-831c-f8ce1a3e1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(tokenizer, domain_data, args, seq_length):\n",
    "    train_data = load_dataset('json', data_files=domain_data, split='train', streaming=True)\n",
    "    no_iter_train_data = load_dataset('json', data_files=domain_data, split='train', streaming=False)\n",
    "    total_train_data_cnt = len(no_iter_train_data)\n",
    "    del no_iter_train_data\n",
    "    gc.collect()\n",
    "\n",
    "    eval_data = load_dataset('json', data_files=domain_data, split='valid', streaming=True)\n",
    "    no_iter_eval_data = load_dataset('json', data_files=domain_data, split='valid', streaming=False)\n",
    "    total_eval_data_cnt = len(no_iter_eval_data)\n",
    "    del no_iter_eval_data\n",
    "    gc.collect()\n",
    "    \n",
    "    train_dataset = Vetorizer(tokenizer, train_data, seq_length, total_train_data_cnt)\n",
    "    eval_dataset = Vetorizer(tokenizer, eval_data, seq_length, total_train_data_cnt)\n",
    "    \n",
    "    return train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c17a1124-01c0-4695-b140-947223cf7891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rouge_scores(references, candidate):\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    scores = rouge.compute(\n",
    "        predictions=candidate,\n",
    "        references=references,\n",
    "        rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "        use_stemmer=True,\n",
    "    )\n",
    "    return scores\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    raw_scores = compute_rouge_scores(\n",
    "        references=decoded_labels,\n",
    "        candidate=decoded_preds\n",
    "    )\n",
    "\n",
    "    flat_scores = {}\n",
    "    for key, score in raw_scores.items():\n",
    "        f = getattr(score.mid, \"fmeasure\", None) or getattr(score, \"fmeasure\")\n",
    "        flat_scores[key] = f * 100\n",
    "\n",
    "    return flat_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc746636-986a-4834-b6a3-37ef85e374ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/e1430a14/.conda/envs/notebook/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = 'paust/pko-t5-small'\n",
    "tokenizer = T5TokenizerFast.from_pretrained(model_ckpt)\n",
    "\n",
    "domain_name = 'law'\n",
    "\n",
    "domain_data = {\n",
    "    'train': f'{domain_name}/train.jsonl',\n",
    "    'valid': f'{domain_name}/valid.jsonl',\n",
    "    'test': f'{domain_name}/test.jsonl'\n",
    "}\n",
    "\n",
    "seq_length = {\n",
    "    'encoder': 2048,\n",
    "    'decoder': 512\n",
    "}\n",
    "\n",
    "final_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./new_text_summarize_model\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_steps=100,\n",
    "    save_steps=500,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=3e-5,\n",
    "    warmup_steps=500,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=512,\n",
    "    generation_num_beams=4\n",
    ")\n",
    "\n",
    "train_dataset, eval_dataset = create_dataset(tokenizer, domain_data, final_args, seq_length)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "final_model = T5ForConditionalGeneration.from_pretrained(model_ckpt).to(device)\n",
    "\n",
    "final_trainer = Seq2SeqTrainer(\n",
    "    model=final_model,\n",
    "    args=final_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(\n",
    "        tokenizer,\n",
    "        model=None,\n",
    "        label_pad_token_id=tokenizer.pad_token_id\n",
    "    ),\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe3f0f3c-8b27-494d-a337-880bfa3db782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "CUDA available: False\n",
      "GPU count: 0\n",
      "Trainer n_gpu: 0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)           # 예: 2.x.x+cu12x\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU count:\", torch.cuda.device_count())\n",
    "# Trainer 내부 캐시 확인\n",
    "print(\"Trainer n_gpu:\", final_trainer.args.n_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bcdbaa0-1955-4a7e-8ac5-9a82b3ab52eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'update'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m optim_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msahur\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m mapvar[optim_type] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgood\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmapvar\u001b[49m\u001b[43m[\u001b[49m\u001b[43moptim_type\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m mapvar\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'update'"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "accuracy_score = evaluate.load(\"accuracy\")\n",
    "\n",
    "# mapvar = {}\n",
    "# optim_type = \"sahur\"\n",
    "# mapvar[optim_type] = \"good\"\n",
    "# mapvar[optim_type].update(\"better\")\n",
    "# mapvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd24101-f87e-4f71-9061-b5ec62e8da14",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_trainer.train()\n",
    "\n",
    "backup_dir = \"./text_summarize_model\"\n",
    "os.makedirs(backup_dir, exist_ok=True)\n",
    "trainer.save_checkpoint(backup_dir)\n",
    "args_path = os.path.join(backup_dir, \"training_args.json\")\n",
    "trainer.args.to_json_file(args_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
